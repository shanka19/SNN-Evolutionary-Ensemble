{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random as r\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Basic LIF Neuron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuron(object):\n",
    "    \n",
    "    def __init__(self, u_rest=0.0, u_thresh=1.0, tau_rest=4.0, r=1.0, tau=10.0):\n",
    "        \n",
    "        # Membrane resting potential in mV\n",
    "        self.u_rest = u_rest\n",
    "        # Membrane threshold potential in mV\n",
    "        self.u_thresh = u_thresh\n",
    "        # Duration of the resting period in ms\n",
    "        self.tau_rest = tau_rest\n",
    "        # Membrane resistance in Ohm\n",
    "        self.r = r\n",
    "        # Membrane time constant in ms\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Instantiate a graph for this neuron\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        # Build the graph\n",
    "        with self.graph.as_default():\n",
    "        \n",
    "            # Variables and placeholders\n",
    "            self.get_vars_and_ph()\n",
    "            \n",
    "            # Operations\n",
    "            self.input = self.get_input_op()\n",
    "            self.potential = self.get_potential_op()\n",
    "            # Note that input is a prerequisite of potential, so it will\n",
    "            # always be evaluated when potential is\n",
    "            \n",
    "    # Variables and placeholders\n",
    "    def get_vars_and_ph(self):\n",
    "\n",
    "        # The current membrane potential\n",
    "        self.u = tf.Variable(self.u_rest, dtype=tf.float32, name='u')\n",
    "        # The duration left in the resting period (0 most of the time except after a neuron spike)\n",
    "        self.t_rest = tf.Variable(0.0, dtype=tf.float32, name='t_rest')\n",
    "        # Input current\n",
    "        self.i_app = tf.placeholder(dtype=tf.float32, name='i_app')\n",
    "        # The chosen time interval for the stimulation in ms\n",
    "        self.dt = tf.placeholder(dtype=tf.float32, name='dt')\n",
    "\n",
    "    # Evaluate input current\n",
    "    def get_input_op(self):\n",
    "        \n",
    "        return self.i_app\n",
    "        \n",
    "    # Neuron behaviour during integration phase (below threshold)\n",
    "    def get_integrating_op(self):\n",
    "\n",
    "        # Get input current\n",
    "        i_op = self.get_input_op()\n",
    "\n",
    "        # Update membrane potential\n",
    "        du_op = tf.divide(tf.subtract(tf.multiply(self.r, i_op), self.u), self.tau) \n",
    "        u_op = self.u.assign_add(du_op * self.dt)\n",
    "        # Refractory period is 0\n",
    "        t_rest_op = self.t_rest.assign(0.0)\n",
    "        \n",
    "        return u_op, t_rest_op\n",
    "\n",
    "    # Neuron behaviour during firing phase (above threshold)    \n",
    "    def get_firing_op(self):                  \n",
    "\n",
    "        # Reset membrane potential\n",
    "        u_op = self.u.assign(self.u_rest)\n",
    "        # Refractory period starts now\n",
    "        t_rest_op = self.t_rest.assign(self.tau_rest)\n",
    "\n",
    "        return u_op, t_rest_op\n",
    "\n",
    "    # Neuron behaviour during resting phase (t_rest > 0)\n",
    "    def get_resting_op(self):\n",
    "\n",
    "        # Membrane potential stays at u_rest\n",
    "        u_op = self.u.assign(self.u_rest)\n",
    "        # Refractory period is decreased by dt\n",
    "        t_rest_op = self.t_rest.assign_sub(self.dt)\n",
    "        \n",
    "        return u_op, t_rest_op\n",
    "\n",
    "    def get_potential_op(self):\n",
    "        \n",
    "        return tf.case(\n",
    "            [\n",
    "                (self.t_rest > 0.0, self.get_resting_op),\n",
    "                (self.u > self.u_thresh, self.get_firing_op),\n",
    "            ],\n",
    "            default=self.get_integrating_op\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A new neuron model derived from the LIF neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes synaptic spikes as input and remember them over a specified time period\n",
    "class LIFSynapticNeuron(LIFNeuron):\n",
    "    \n",
    "    def __init__(self, n_syn, w, max_spikes=50, u_rest=0.0, u_thresh=1.0, tau_rest=4.0, r=1.0, tau=10.0, q=1.5, tau_syn=5.0):\n",
    "      \n",
    "        # Number of synapses\n",
    "        self.n_syn = n_syn\n",
    "        # Maximum number of spikes we remember\n",
    "        self.max_spikes = max_spikes\n",
    "        # The neuron synaptic 'charge'\n",
    "        self.q = q\n",
    "        # The synaptic time constant (ms)\n",
    "        self.tau_syn = tau_syn\n",
    "        # The synaptic efficacy\n",
    "        self.w = w\n",
    "\n",
    "        super(LIFSynapticNeuron, self).__init__(u_rest, u_thresh, tau_rest, r, tau)\n",
    "    \n",
    "    # Update the parent graph variables and placeholders\n",
    "    def get_vars_and_ph(self):\n",
    "        \n",
    "        # Get parent grah variables and placeholders\n",
    "        super(LIFSynapticNeuron, self).get_vars_and_ph()\n",
    "\n",
    "        # Add ours\n",
    "        \n",
    "        # The history of synaptic spike times for the neuron \n",
    "        self.t_spikes = tf.Variable(tf.constant(-1.0, shape=[self.max_spikes, self.n_syn], dtype=tf.float32))\n",
    "        # The last index used to insert spike times\n",
    "        self.t_spikes_idx = tf.Variable(self.max_spikes-1, dtype=tf.int32)\n",
    "        # A placeholder indicating which synapse spiked in the last time step\n",
    "        self.syn_has_spiked = tf.placeholder(shape=[self.n_syn], dtype=tf.bool)\n",
    "\n",
    "    # Operation to update spike times\n",
    "    def update_spike_times(self):\n",
    "        \n",
    "        # Increase the age of older spikes\n",
    "        old_spikes_op = self.t_spikes.assign_add(tf.where(self.t_spikes >=0,\n",
    "                                                          tf.constant(1.0, shape=[self.max_spikes, self.n_syn]) * self.dt,\n",
    "                                                          tf.zeros([self.max_spikes, self.n_syn])))\n",
    "\n",
    "        # Increment last spike index (modulo max_spikes)\n",
    "        new_idx_op = self.t_spikes_idx.assign(tf.mod(self.t_spikes_idx + 1, self.max_spikes))\n",
    "\n",
    "        # Create a list of coordinates to insert the new spikes\n",
    "        idx_op = tf.constant(1, shape=[self.n_syn], dtype=tf.int32) * new_idx_op\n",
    "        coord_op = tf.stack([idx_op, tf.range(self.n_syn)], axis=1)\n",
    "\n",
    "        # Create a vector of new spike times (non-spikes are assigned a negative time)\n",
    "        new_spikes_op = tf.where(self.syn_has_spiked,\n",
    "                                 tf.constant(0.0, shape=[self.n_syn]),\n",
    "                                 tf.constant(-1.0, shape=[self.n_syn]))\n",
    "        \n",
    "        # Replace older spikes by new ones\n",
    "        return tf.scatter_nd_update(old_spikes_op, coord_op, new_spikes_op)\n",
    "\n",
    "    # Override parent get_input_op method\n",
    "    def get_input_op(self):\n",
    "        \n",
    "        # Update our memory of spike times with the new spikes\n",
    "        t_spikes_op = self.update_spike_times()\n",
    "\n",
    "        # Evaluate synaptic input current for each spike on each synapse\n",
    "        i_syn_op = tf.where(t_spikes_op >=0,\n",
    "                            self.q/self.tau_syn * tf.exp(tf.negative(t_spikes_op/self.tau_syn)),\n",
    "                            t_spikes_op*0.0)\n",
    "\n",
    "        # Add each synaptic current to the input current\n",
    "        i_op =  tf.reduce_sum(self.w * i_syn_op)\n",
    "        \n",
    "        return tf.add(self.i_app, i_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIF Neuron for Synaptic Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuron(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_syn, w, max_spikes=None, \n",
    "                 p_rest=0.0, tau_rest=1.0, tau_m=10.0, tau_s=2.5, T=None,\n",
    "                 K=2.1, K1=2.0, K2=4.0):\n",
    "\n",
    "        # Model parameters\n",
    "\n",
    "        # Membrane resting potential\n",
    "        self.p_rest = p_rest\n",
    "        \n",
    "        # Duration of the recovery period\n",
    "        self.tau_rest = tau_rest\n",
    "        \n",
    "        # Membrane time constant\n",
    "        self.tau_m = tau_m\n",
    "        \n",
    "        # Synaptic time constant\n",
    "        self.tau_s = tau_s\n",
    "        \n",
    "        # Spiking threshold\n",
    "        if T is None:\n",
    "            self.T = n_syn/4\n",
    "        else:\n",
    "            self.T = T\n",
    "        \n",
    "        # Model constants\n",
    "        self.K = K\n",
    "        self.K1 = K1\n",
    "        self.K2 = K2\n",
    "\n",
    "        # The number of synapses\n",
    "        self.n_syn = n_syn\n",
    "        \n",
    "        # The incoming spike times memory window\n",
    "        if max_spikes is None:\n",
    "            self.max_spikes = 70\n",
    "        else:\n",
    "            self.max_spikes = max_spikes\n",
    "\n",
    "        # Instantiate a specific tensorflow graph for the Neuron Model\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        ################################\n",
    "        # Build the neuron model graph #\n",
    "        ################################\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            ##############################\n",
    "            # Variables and placeholders #\n",
    "            ##############################    \n",
    "            self.get_vars_and_ph(w)\n",
    "            \n",
    "            ##############\n",
    "            # Operations #\n",
    "            ##############\n",
    "            self.potential = self.get_potential_op()\n",
    "\n",
    "    ###############################################\n",
    "    # Define the graph Variables and placeholders #\n",
    "    ###############################################\n",
    "    def get_vars_and_ph(self, w):\n",
    "\n",
    "        # Placeholders (ie things that are passed to the graph as inputs)\n",
    "        \n",
    "        # A boolean tensor indicating which synapses have spiked during dt\n",
    "        self.new_spikes = tf.placeholder(shape=[self.n_syn], dtype=tf.bool, name='new_spikes')\n",
    "\n",
    "        # The time increment since the last update\n",
    "        self.dt = tf.placeholder(dtype=tf.float32, name='dt')\n",
    "        \n",
    "        # Variables (ie things that are modified by the graph at runtime)\n",
    "\n",
    "        # The neuron memory of incoming spike times\n",
    "        self.t_spikes = tf.Variable(tf.constant(100000.0, shape=[self.max_spikes, self.n_syn]), dtype=tf.float32)\n",
    "        \n",
    "        # The last spike time insertion index\n",
    "        self.t_spikes_idx = tf.Variable(self.n_syn - 1, dtype=tf.int32)\n",
    "\n",
    "        # The relative time since the last spike (assume it was a very long time ago)\n",
    "        self.last_spike = tf.Variable(1000.0, dtype=tf.float32, name='last_spike')\n",
    "        \n",
    "        # The membrane potential\n",
    "        self.p = tf.Variable(self.p_rest,dtype=tf.float32, name='p')\n",
    "        \n",
    "        # The duration remaining in the resting period (between 0 and self.tau_s)\n",
    "        self.t_rest = tf.Variable(0.0,dtype=tf.float32, name='t_rest')\n",
    "        \n",
    "        # The synapse efficacy weights\n",
    "        self.w = tf.Variable(w)\n",
    "\n",
    "    # Excitatory post-synaptic potential (EPSP)\n",
    "    def epsilon_op(self):\n",
    "\n",
    "        # We only use the negative value of the relative spike times\n",
    "        spikes_t_op = tf.negative(self.t_spikes)\n",
    "\n",
    "        return self.K *(tf.exp(spikes_t_op/self.tau_m) - tf.exp(spikes_t_op/self.tau_s))\n",
    "    \n",
    "    # Membrane spike response\n",
    "    def eta_op(self):\n",
    "        \n",
    "        # We only use the negative value of the relative time\n",
    "        t_op = tf.negative(self.last_spike)\n",
    "        \n",
    "        # Evaluate the spiking positive pulse\n",
    "        pos_pulse_op = self.K1 * tf.exp(t_op/self.tau_m)\n",
    "        \n",
    "        # Evaluate the negative spike after-potential\n",
    "        neg_after_op = self.K2 * (tf.exp(t_op/self.tau_m) - tf.exp(t_op/self.tau_s))\n",
    "\n",
    "        # Evaluate the new post synaptic membrane potential\n",
    "        return self.T * (pos_pulse_op - neg_after_op)\n",
    "    \n",
    "    # Neuron behaviour during integrating phase (t_rest = 0)\n",
    "    def w_epsilons_op(self):\n",
    "        \n",
    "        # Evaluate synaptic EPSPs. We ignore synaptic spikes older than the last neuron spike\n",
    "        epsilons_op = tf.where(tf.logical_and(self.t_spikes >=0, self.t_spikes < self.last_spike - self.tau_rest),\n",
    "                               self.epsilon_op(),\n",
    "                               self.t_spikes*0.0)\n",
    "                          \n",
    "        # Agregate weighted incoming EPSPs \n",
    "        return tf.reduce_sum(self.w * epsilons_op)\n",
    "\n",
    "    # Neuron behaviour during resting phase (t_rest > 0)\n",
    "    def post_firing_p_op(self):\n",
    "   \n",
    "        # Membrane potential is only impacted by the last post-synaptic spike (ignore EPSPs)\n",
    "        return self.eta_op()\n",
    "    \n",
    "    def update_spikes_times(self):\n",
    "        \n",
    "        # Increase the age of all the existing spikes by dt\n",
    "        old_spikes_op = self.t_spikes.assign_add(tf.ones(tf.shape(self.t_spikes), dtype=tf.float32) * self.dt)\n",
    "\n",
    "        # Increment last spike index (modulo max_spikes)\n",
    "        new_idx_op = self.t_spikes_idx.assign(tf.mod(self.t_spikes_idx + 1, self.max_spikes))\n",
    "\n",
    "        # Create a list of coordinates to insert the new spikes\n",
    "        idx_op = tf.constant(1, shape=[self.n_syn], dtype=tf.int32) * new_idx_op\n",
    "        coord_op = tf.stack([idx_op, tf.range(self.n_syn)], axis=1)\n",
    "\n",
    "        # Create a vector of new spike times (non-spikes are assigned a very high time)\n",
    "        new_spikes_op = tf.where(self.new_spikes,\n",
    "                                 tf.constant(0.0, shape=[self.n_syn]),\n",
    "                                 tf.constant(100000.0, shape=[self.n_syn]))\n",
    "        \n",
    "        # Replace older spikes by new ones\n",
    "        return tf.scatter_nd_update(old_spikes_op, coord_op, new_spikes_op)\n",
    "    \n",
    "    def resting_w_op(self):\n",
    "        \n",
    "        # For the base LIF Neuron, the weights remain constants when resting\n",
    "        return tf.identity(self.w)\n",
    "    \n",
    "    def default_w_op(self):\n",
    "        \n",
    "        # For the base LIF Neuron, the weights remain constants when integrating\n",
    "        return tf.identity(self.w)\n",
    "\n",
    "    def firing_w_op(self):\n",
    "\n",
    "        # For the base LIF Neuron, the weights remain constants when firing\n",
    "        return tf.identity(self.w)\n",
    "    \n",
    "    def resting_op(self):\n",
    "        \n",
    "        # Update weights\n",
    "        w_op = self.resting_w_op()\n",
    "        \n",
    "        # Update the resting period\n",
    "        t_rest_op = self.t_rest.assign(tf.maximum(self.t_rest - self.dt, 0.0))\n",
    "        \n",
    "        # During the resting period, the membrane potential is only given by the eta kernel\n",
    "        with tf.control_dependencies([w_op, t_rest_op]):\n",
    "            return self.eta_op()\n",
    "    \n",
    "    def firing_op(self):\n",
    "\n",
    "        # Update weights\n",
    "        w_op = self.firing_w_op()\n",
    "        \n",
    "        # Reset the time of the last spike, but only once the weights have been updated\n",
    "        with tf.control_dependencies([w_op]):\n",
    "            last_spike_op = self.last_spike.assign(0.0)\n",
    "\n",
    "        # Start the resting period\n",
    "        t_rest_op = self.t_rest.assign(self.tau_rest)\n",
    "        \n",
    "        # At spiking time, the membrane potential is only given by the eta kernel\n",
    "        with tf.control_dependencies([last_spike_op, t_rest_op]):\n",
    "            return self.eta_op()\n",
    "        \n",
    "    def default_op(self):\n",
    "        \n",
    "        # Update weights\n",
    "        w_op = self.default_w_op()\n",
    "        \n",
    "        # By default, the membrane potential is given by the sum of the eta kernel and the weighted epsilons\n",
    "        with tf.control_dependencies([w_op]):\n",
    "            return self.eta_op() + self.w_epsilons_op()\n",
    "        \n",
    "    def integrating_op(self):\n",
    "\n",
    "        # Evaluate the new membrane potential, integrating both synaptic input and spike dynamics\n",
    "        p_op = self.eta_op() + self.w_epsilons_op()\n",
    "\n",
    "        # We have a different behavior if we reached the threshold\n",
    "        return tf.cond(p_op > self.T,\n",
    "                       self.firing_op,\n",
    "                       self.default_op)\n",
    "    \n",
    "    def get_potential_op(self):\n",
    "        \n",
    "        # Update our internal memory of the synapse spikes (age older spikes, add new ones)\n",
    "        update_spikes_op = self.update_spikes_times()\n",
    "        \n",
    "        # Increase the relative time of the last spike by the time elapsed\n",
    "        last_spike_age_op = self.last_spike.assign_add(self.dt)\n",
    "        \n",
    "        # Update the internal state of the neuron and evaluate membrane potential\n",
    "        with tf.control_dependencies([update_spikes_op, last_spike_age_op]):\n",
    "            return tf.cond(self.t_rest > 0.0,\n",
    "                           self.resting_op,\n",
    "                           self.integrating_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A class that generates random spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeTrains(object):\n",
    "    \n",
    "    def __init__(self, n_syn, r_min=0.0, r_max=90.0, r=None, s_max=1800, ds_max=360, s=None, auto_vrate=True, delta_max=0):\n",
    "        \n",
    "        # Number of synapses\n",
    "        self.n_syn = n_syn\n",
    "        # Minimum and maximum spiking rate (in Hz)\n",
    "        self.r_min = r_min\n",
    "        self.r_max = r_max\n",
    "        # Spiking rate for each synapse (in Hz)\n",
    "        if r is None:\n",
    "            self.r = np.random.uniform(self.r_min, self.r_max, size=(n_syn))\n",
    "        else:\n",
    "            self.r = r\n",
    "        # Rate variation parameters\n",
    "        self.s_max = s_max\n",
    "        self.ds_max = ds_max\n",
    "        # Rate variation\n",
    "        if s is None:\n",
    "            self.s = np.random.uniform(-self.s_max, self.s_max, size=(self.n_syn))\n",
    "        else:\n",
    "            self.s = s\n",
    "        # Automatically apply rate variation when\n",
    "        self.auto_vrate = auto_vrate\n",
    "        # Maximum time between two spikes on each synapse (0 means no maximum) in ms\n",
    "        self.delta_max = delta_max\n",
    "\n",
    "        # Memory of spikes\n",
    "        self.spikes = None\n",
    "    \n",
    "    # Generate new spikes for the specified time interval (in ms)\n",
    "    # The new spikes are added to the existing spike trains.\n",
    "    # The method returns only the new set of spikes\n",
    "    def add_spikes(self, t):\n",
    "        \n",
    "        for step in range(t):\n",
    "            # Draw a random number for each synapse\n",
    "            x = np.random.uniform(0,1, size=(self.n_syn))\n",
    "            # Each synapse spikes if the drawn number is lower than the probablity\n",
    "            # given by the integration of the rate over one millisecond\n",
    "            spikes = x < self.r * 1e-3\n",
    "            # Keep a memory of our spikes\n",
    "            if self.spikes is None:\n",
    "                self.spikes = np.array([spikes])\n",
    "            else:\n",
    "                if self.delta_max > 0:\n",
    "                    # We force each synapse to spike at least every delta_max ms\n",
    "                    if self.spikes.shape[0] < self.delta_max - 1:\n",
    "                        # At the beginning of the trains, we try to 'fill' as much holes\n",
    "                        # as possible to avoid a 'wall of spikes' when we reach delta_max.\n",
    "                        # For each synapse, count non-zero items\n",
    "                        n_spikes = np.count_nonzero(self.spikes, axis=0)\n",
    "                        # Draw a random number for each synapse \n",
    "                        r = np.random.uniform(0.0, 1.0, size=self.n_syn)\n",
    "                        # The closer we get to delta_max, the higher probability we have to force a spike\n",
    "                        forced_spikes = r < step * 1.0/self.delta_max\n",
    "                        # Modify our random vector of spikes for synapse that did not spike\n",
    "                        spikes = np.where(n_spikes > 0, spikes, spikes | forced_spikes)\n",
    "                    else:\n",
    "                        # Get the last delta_max -1 spike trains\n",
    "                        last_spikes = self.spikes[-(self.delta_max - 1):,:]\n",
    "                        # For each synapse, count non-zero items\n",
    "                        n_spikes = np.count_nonzero(last_spikes, axis=0)\n",
    "                        # Modify spikes to force a spike on synapses where the spike count is zero\n",
    "                        spikes = np.where(n_spikes > 0, spikes, True)\n",
    "                # Store spikes\n",
    "                self.spikes = np.append(self.spikes, [spikes], axis=0)\n",
    "            if self.auto_vrate:\n",
    "                self.change_rate()\n",
    "\n",
    "        return self.spikes[-t:,:]\n",
    "    \n",
    "    # Format a list of spike indexes\n",
    "    def get_spikes(self):\n",
    "        \n",
    "        real_spikes = np.argwhere(self.spikes > 0)\n",
    "        # We prefer having spikes in the range [1..n_syn]\n",
    "        spike_index = real_spikes[:,1] + 1\n",
    "        spike_timings = real_spikes[:,0]\n",
    "        \n",
    "        return spike_timings, spike_index\n",
    "    \n",
    "    # Change rate, applying the specified delta in Hz\n",
    "    def change_rate(self, delta=None):\n",
    "\n",
    "        # Update spiking rate\n",
    "        if delta is None:\n",
    "            delta = self.s\n",
    "        self.r = np.clip( self.r + delta, self.r_min, self.r_max)\n",
    "        # Update spiking rate variation\n",
    "        ds = np.random.uniform(-self.ds_max, self.ds_max, size=(self.n_syn))\n",
    "        self.s = np.clip( self.s + ds, -self.s_max, self.s_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Spatio Temporal Classification using SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Spike Trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "spike_times = []\n",
    "for i in range(0,5):\n",
    "    s = np.random.randint(low=1,high=199,size=200)\n",
    "    spike_times.append(s)\n",
    "\n",
    "spike_train = []\n",
    "for i in range(0,5):\n",
    "    s = np.zeros((200,200),dtype = bool)\n",
    "    spike_train.append(s)\n",
    "\n",
    "for i in range(0,5):\n",
    "    for j in range(0,200):\n",
    "        k = spike_times[i][j]\n",
    "        spike_train[i][k][j] = True\n",
    "\n",
    "# Desired Spike Times\n",
    "desired_spike_times_list = []\n",
    "desired = [33,66,99,132,165]\n",
    "for i in range(0,5):\n",
    "    desired_spike_times_list.append(desired[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Task using SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snn(weights):\n",
    "    T = 200\n",
    "    # Duration of each time step in ms\n",
    "    dt = 1.0\n",
    "    # Number of iterations = T/dt\n",
    "    steps = int(T / dt)\n",
    "    # Number of synapses\n",
    "    n_syn = 200\n",
    "    # Our random spike trains\n",
    "    spike_trains = SpikeTrains(n_syn)\n",
    "    # Generate spikes over the specified period\n",
    "    syn_has_spiked = spike_trains.add_spikes(T)\n",
    "    #Generate boolean spike trains corresponding to the above spike times\n",
    "    syn_has_spiked = spike_train \n",
    "\n",
    "    # We define the base synaptic efficacy as a uniform vector\n",
    "    # Output variables\n",
    "    P = []\n",
    "    W = np.copy(weights)\n",
    "    # Instantiate our LIF neuron\n",
    "    neuron = LIFNeuron(n_syn, W,T=20)\n",
    "    actual_spike_times_list = []\n",
    "    \n",
    "    with tf.Session(graph=neuron.graph) as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for batch in range(0,5):\n",
    "            \n",
    "            actual_spike_times = []\n",
    "            \n",
    "            for step in range(steps):\n",
    "                t = step * dt\n",
    "                feed = { neuron.new_spikes: syn_has_spiked[batch][step], neuron.dt: dt}\n",
    "                p = sess.run(neuron.potential, feed_dict=feed)\n",
    "                P.append((t,p))\n",
    "                if(p>20):\n",
    "                    actual_spike_times.append(step)    \n",
    "            \n",
    "            actual_spike_times_list.append(actual_spike_times)\n",
    "    return(actual_spike_times_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithm 1 - Real Coded Genetic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(desired_times,population):\n",
    "    diff = []\n",
    "    diff_list = []\n",
    "    s = []\n",
    "    l = 0\n",
    "    actual_spike_times_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    for i in range(0,len(population)):\n",
    "        actual_spike_times_list.append(snn(population[i]))\n",
    "    \n",
    "    for i in range(0,len(actual_spike_times_list)):\n",
    "        for j in range(0,len(actual_spike_times_list[i])):\n",
    "            if(len(actual_spike_times_list[i][j])!=0):\n",
    "                for k in range(0,len(actual_spike_times_list[i][j])):\n",
    "                    s.append(actual_spike_times_list[i][j][k] - desired_times[l])\n",
    "            else:\n",
    "                    s.append(0-desired_times[l])\n",
    "            l= l + 1\n",
    "            diff.append(np.mean(np.absolute(s)))\n",
    "            s = []\n",
    "        l=0\n",
    "        diff_list = np.array(diff)\n",
    "        diff = []\n",
    "        err = np.where(diff_list>=3)\n",
    "        acc = 100 - (len(err[0])/len(diff_list))*100\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    return(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[75.46666666666667, 52.354838709677416, 53.15625, 54.44827586206897, 71.06666666666666]\n",
      "(array([0, 1, 2, 3, 4], dtype=int64),)\n",
      "[74.78125, 54.166666666666664, 53.1, 55.56666666666667, 73.3030303030303]\n",
      "(array([0, 1, 2, 3, 4], dtype=int64),)\n",
      "[77.06451612903226, 56.225806451612904, 52.9, 56.516129032258064, 71.56666666666666]\n",
      "(array([0, 1, 2, 3, 4], dtype=int64),)\n",
      "[74.96428571428571, 52.407407407407405, 53.096774193548384, 54.70967741935484, 68.73333333333333]\n",
      "(array([0, 1, 2, 3, 4], dtype=int64),)\n",
      "[72.58620689655173, 50.42857142857143, 54.42857142857143, 54.064516129032256, 76.06451612903226]\n",
      "(array([0, 1, 2, 3, 4], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = []\n",
    "for i in range(0,5):\n",
    "    s = np.float32(np.random.uniform(low=0,high=25,size=200))\n",
    "    population.append(s)\n",
    "\n",
    "fitness_function([33,66,99,132,165],population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(p1,p2):\n",
    "    h1 = 0.5*p1 + 0.5*p2\n",
    "    h2 = 1.5*p1 - 0.5*p2\n",
    "    h3 = 1.5*p2 - 0.5*p1\n",
    "    return(h1,h2,h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(solution,max_solution,min_solution,current_gen,max_gen):\n",
    "    rand = np.random.uniform(0,1)\n",
    "    if(rand<=0.5):\n",
    "        tau = 1\n",
    "    else:\n",
    "        tau = -1\n",
    "    b = 1\n",
    "    d = math.pow((1 - (current_gen/max_gen)),b)\n",
    "    new_solution = solution + tau*(max_solution - min_solution)*(1-math.pow(rand,d))\n",
    "    return(new_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(population,desired_times,num_epochs):\n",
    "    \n",
    "    for epochs in range(0,num_epochs):\n",
    "    # Compute Fitness Value of entire population and store it in a list\n",
    "    \n",
    "        fitness = fitness_function(desired_times,population)\n",
    "\n",
    "        fitness_copy = fitness\n",
    "\n",
    "        indexes = np.argsort(-np.array(fitness))\n",
    "        fitness = -np.sort(-np.array(fitness))\n",
    "\n",
    "        index = indexes[0:2]\n",
    "\n",
    "        # Compare fitness values of population and pick best 2 parents\n",
    "\n",
    "        parent_1 = population[index[0]]\n",
    "        parent_2 = population[index[1]]\n",
    "\n",
    "        # Do crossover to get 2 children \n",
    "\n",
    "        child_1,child_2,child_3 = crossover(parent_1,parent_2)\n",
    "\n",
    "        # Decide whether to add them to population based on their fitness\n",
    "\n",
    "        children = []\n",
    "        children.extend([child_1,child_2,child_3])\n",
    "        population.append(child_1)\n",
    "        population.append(child_2)\n",
    "        population.append(child_3)\n",
    "\n",
    "        fitness_copy.extend(fitness_function(desired_times,children))\n",
    "\n",
    "        index = np.argsort(-np.array(fitness_copy))\n",
    "        fitness_copy = -np.sort(-np.array(fitness_copy))\n",
    "\n",
    "        index_remove = index[len(index)-4:len(index)-1]\n",
    "        fitness_copy = [i for j, i in enumerate(fitness_copy) if j not in index_remove]\n",
    "        population = [i for j, i in enumerate(population) if j not in index_remove]\n",
    "    \n",
    "        # Sort again to get indexes of best and worst solution get indexes\n",
    "        \n",
    "        index = np.argsort(-np.array(fitness_copy))\n",
    "        best_solution = population[index[0]]\n",
    "        worst_solution = population[index[len(index)-1]]\n",
    "        \n",
    "        # Do mutation\n",
    "        \n",
    "        for i in range(0,len(population)):\n",
    "            population[i] = mutation(population[i],best_solution,worst_solution,epochs,num_epochs)\n",
    "            population[i][population[i]>15] = 15\n",
    "            population[i][population[i]<-15] = -15\n",
    "        \n",
    "        fitness_copy = fitness_function(desired_times,population)\n",
    "\n",
    "    return(fitness_copy,population)\n",
    "    \n",
    "    # End GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68, 122, 141], [49, 84, 191], [99], [2, 21, 103, 125, 132], [3, 40, 159, 170]]\n"
     ]
    }
   ],
   "source": [
    "##### Test Here!!\n",
    "T = 200\n",
    "# Duration of each time step in ms\n",
    "dt = 1.0\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Number of synapses\n",
    "n_syn = 200\n",
    "# Our random spike trains\n",
    "spike_trains = SpikeTrains(n_syn)\n",
    "# Generate spikes over the specified period\n",
    "syn_has_spiked = spike_trains.add_spikes(T)\n",
    "#Generate boolean spike trains corresponding to the above spike times\n",
    "syn_has_spiked = spike_train \n",
    "neuron = LIFNeuron(n_syn, weights[48],T=20)\n",
    "actual_spike_times_list = []\n",
    "P = []\n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for batch in range(0,5):\n",
    "            \n",
    "        actual_spike_times = []\n",
    "            \n",
    "        for step in range(steps):\n",
    "            t = step * dt\n",
    "            feed = { neuron.new_spikes: syn_has_spiked[batch][step], neuron.dt: dt}\n",
    "            p = sess.run(neuron.potential, feed_dict=feed)\n",
    "            P.append((t,p))\n",
    "            if(p>20):\n",
    "                actual_spike_times.append(step)    \n",
    "            \n",
    "        actual_spike_times_list.append(actual_spike_times)\n",
    "print(actual_spike_times_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = []\n",
    "for i in range(0,50):\n",
    "    s = np.float32(np.random.uniform(low=-15,high=15,size=200))\n",
    "    population.append(s)\n",
    "\n",
    "fit,weights = genetic_algorithm(population,[33,66,99,132,165],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithm 2 - Differential Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de(fobj, bounds, mut=0.8, crossp=0.7, popsize=20, its=1000): # fobj can be a list of fitness values, bounds on values\n",
    "    dimensions = len(bounds)\n",
    "    pop = np.random.rand(popsize, dimensions)\n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    \n",
    "    diff = np.fabs(min_b - max_b)\n",
    "    pop_denorm = min_b + pop * diff\n",
    "    fitness = np.asarray([fobj(ind) for ind in pop_denorm])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = pop_denorm[best_idx]\n",
    "    \n",
    "    for i in range(its):\n",
    "        for j in range(popsize):\n",
    "            idxs = [idx for idx in range(popsize) if idx != j]\n",
    "            a, b, c = pop[np.random.choice(idxs, 3, replace = False)]\n",
    "            mutant = np.clip(a + mut * (b - c), 0, 1)\n",
    "            cross_points = np.random.rand(dimensions) < crossp\n",
    "            \n",
    "            if not np.any(cross_points):\n",
    "                cross_points[np.random.randint(0, dimensions)] = True\n",
    "            trial = np.where(cross_points, mutant, pop[j])\n",
    "            trial_denorm = min_b + trial * diff\n",
    "            f = fobj(trial_denorm)\n",
    "            \n",
    "            if f < fitness[j]:\n",
    "                fitness[j] = f\n",
    "                pop[j] = trial\n",
    "                if f < fitness[best_idx]:\n",
    "                    best_idx = j\n",
    "                    best = trial_denorm\n",
    "        \n",
    "        yield best, fitness[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Algorithm 3 - Particle Swarm Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso_initialize(pop_size):\n",
    "    pos = []\n",
    "    vel = []\n",
    "    for i in range(0,pop_size):\n",
    "        s = np.random.uniform(0,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
